{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook tests the data by spliting so the same event cannot be included in both the training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import build-in\n",
    "import numpy as np\n",
    "\n",
    "# import local\n",
    "import utility_classification as ut_cla\n",
    "import labels_create_ENSO2 as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up path to data\n",
    "path = '/home/nicola/Documents/classification_clean/data/regions/'\n",
    "\n",
    "#create dictionary with all input data\n",
    "dict_data_struc ={\n",
    "        1:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6},\n",
    "        2:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6},\n",
    "        3:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6},\n",
    "        4:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6},\n",
    "        5:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6},\n",
    "        6:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' :42,\n",
    "           'firstmon' :6},\n",
    "        7:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6},\n",
    "        8:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6},\n",
    "        9:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6},\n",
    "        10:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6}, \n",
    "        11:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6},\n",
    "        12:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6},\n",
    "        13:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6},\n",
    "        14:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6},\n",
    "        15:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :6}, \n",
    "        16:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :6},\n",
    "        17:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :6},\n",
    "        18:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :6},\n",
    "        19:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :6},\n",
    "        20:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :6}, \n",
    "        21:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :6},\n",
    "        22:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :6},\n",
    "        23:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :6},\n",
    "        24:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :6},\n",
    "        25:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :6},       \n",
    "        26:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :6},\n",
    "        27:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :6},\n",
    "        28:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :6},\n",
    "        29:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :6},\n",
    "        30:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :6},\n",
    "        31:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :6},\n",
    "        32:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :6},\n",
    "        33:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :6},\n",
    "        34:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :6},\n",
    "        35:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :6}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process all data\n",
    "result = ut_cla.preprocess_from_dict2(dict_data_struc, path, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the data for each of the three long timeseries\n",
    "input_ER1=np.concatenate([result[1],result[2],result[3],result[4],result[5]],axis=1)\n",
    "input_ER2=np.concatenate([result[6],result[7],result[8],result[9],result[10]],axis=1)\n",
    "input_ER3=np.concatenate([result[11],result[12],result[13],result[14],result[15]],axis=1)\n",
    "input_CO1=np.concatenate([result[16],result[17],result[18],result[19],result[20]],axis=1)\n",
    "input_CO2=np.concatenate([result[21],result[22],result[23],result[24],result[25]],axis=1)\n",
    "input_KP=np.concatenate([result[26],result[27],result[28],result[29],result[30]],axis=1)\n",
    "input_HAD=np.concatenate([result[31],result[32],result[33],result[34],result[35]],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_HAD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create labels\n",
    "labels_train,labels_test=labels.create_labels()\n",
    "labels_test2=labels_test\n",
    "labels_data=[i for i in range(123)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the machine learning tools\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#Ensemble class scores: random train/test\n",
    "\n",
    "a_score=[0 for i in range(10)]\n",
    "p_score_CP=[0 for i in range(10)]\n",
    "p_score_EL=[0 for i in range(10)]\n",
    "p_score_LN=[0 for i in range(10)]\n",
    "p_score_NE=[0 for i in range(10)]\n",
    "r_score_CP=[0 for i in range(10)]\n",
    "r_score_EL=[0 for i in range(10)]\n",
    "r_score_LN=[0 for i in range(10)]\n",
    "r_score_NE=[0 for i in range(10)]\n",
    "clf_score=[0 for i in range(10)]\n",
    "\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = RandomForestClassifier(max_depth=100)\n",
    "clf4 = MLPClassifier(alpha=0.01,hidden_layer_sizes=(500, ), max_iter=1500)\n",
    "\n",
    "\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('kNN', clf1),('RF', clf3), ('NN', clf4)], voting='soft')#, weights=[2, 1, 2, 1])\n",
    "\n",
    "\n",
    "for x in range(0, 10):\n",
    "    print(x)\n",
    "\n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2)\n",
    "\n",
    "    input_train=np.concatenate([input_HAD[input_idx,:],input_CO1[input_idx,:],input_CO2[input_idx,:],input_ER1[input_idx,:],input_ER2[input_idx,:],input_ER3[input_idx,:],input_KP[input_idx,:]],axis=0)\n",
    "    input_test=np.concatenate([input_HAD[input_test_idx,:],input_CO1[input_test_idx,:],input_CO2[input_test_idx,:],input_ER1[input_test_idx,:],input_ER2[input_test_idx,:],input_ER3[input_test_idx,:],input_KP[input_test_idx,:]],axis=0)\n",
    "\n",
    "    labels_train=labels_traina + labels_traina + labels_traina + labels_traina + labels_traina +labels_traina + labels_traina\n",
    "    labels_test=labels_testa+labels_testa+labels_testa + labels_testa+labels_testa+labels_testa + labels_testa\n",
    "\n",
    "    #choose classifier to be \n",
    "    clf1 = clf1.fit(input_train, labels_train)\n",
    "   # clf2 = clf2.fit(input_train, labels_train)\n",
    "    clf3 = clf3.fit(input_train, labels_train)\n",
    "    clf4 = clf4.fit(input_train, labels_train)\n",
    "    eclf = eclf.fit(input_train, labels_train)\n",
    "    pred=eclf.predict(input_test)\n",
    "    a_score[x]=accuracy_score(labels_test, pred)\n",
    "    p_score_CP[x]=precision_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    p_score_EL[x]=precision_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    p_score_LN[x]=precision_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    p_score_NE[x]=precision_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    r_score_CP[x]=recall_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    r_score_EL[x]=recall_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    r_score_LN[x]=recall_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    r_score_NE[x]=recall_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    clf_score[x]=cross_val_score(eclf, input_train, labels_train, cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc mean 0.7705069124423963\n",
      "acc max 0.8387096774193549\n",
      "acc min 0.6497695852534562\n",
      "CP mean 0.776075284364758\n",
      "CP max 1.0\n",
      "CP min 0.3157894736842105\n",
      "EL mean 0.621824665330229\n",
      "EL max 0.8809523809523809\n",
      "EL min 0.3611111111111111\n",
      "LN mean 0.7956787856925946\n",
      "LN max 0.9393939393939394\n",
      "LN min 0.6\n",
      "NE mean 0.8172854794182856\n",
      "NE max 0.957983193277311\n",
      "NE min 0.6833333333333333\n",
      "clf mean 0.9739232073643409\n",
      "clf max 0.9844718992248062\n",
      "clf min 0.9643168604651162\n",
      "R-NE mean 0.8055340469521142\n",
      "R-NE max 0.8968253968253969\n",
      "R-NE min 0.7410714285714286\n",
      "R-CP mean 0.5255102040816327\n",
      "R-CP max 0.9285714285714286\n",
      "R-CP min 0.14285714285714285\n",
      "R-EL mean 0.8851020408163265\n",
      "R-EL max 1.0\n",
      "R-EL min 0.7857142857142857\n",
      "R-LN mean 0.7809637188208616\n",
      "R-LN max 0.9285714285714286\n",
      "R-LN min 0.6571428571428571\n",
      "R-NE mean 0.8055340469521142\n",
      "R-NE max 0.8968253968253969\n",
      "R-NE min 0.7410714285714286\n"
     ]
    }
   ],
   "source": [
    "print('acc mean',np.mean(a_score))\n",
    "print('acc max',np.max(a_score))\n",
    "print('acc min',np.min(a_score))\n",
    "\n",
    "print('CP mean',np.mean(p_score_CP))\n",
    "print('CP max',np.max(p_score_CP))\n",
    "print('CP min',np.min(p_score_CP))\n",
    "\n",
    "print('EL mean',np.mean(p_score_EL))\n",
    "print('EL max',np.max(p_score_EL))\n",
    "print('EL min',np.min(p_score_EL))\n",
    "\n",
    "print('LN mean',np.mean(p_score_LN))\n",
    "print('LN max',np.max(p_score_LN))\n",
    "print('LN min',np.min(p_score_LN))\n",
    "\n",
    "print('NE mean',np.mean(p_score_NE))\n",
    "print('NE max',np.max(p_score_NE))\n",
    "print('NE min',np.min(p_score_NE))\n",
    "\n",
    "print('clf mean',np.mean(clf_score))\n",
    "print('clf max',np.max(clf_score))\n",
    "print('clf min',np.min(clf_score))\n",
    "\n",
    "print('R-NE mean',np.mean(r_score_NE))\n",
    "print('R-NE max',np.max(r_score_NE))\n",
    "print('R-NE min',np.min(r_score_NE))\n",
    "\n",
    "print('R-CP mean',np.mean(r_score_CP))\n",
    "print('R-CP max',np.max(r_score_CP))\n",
    "print('R-CP min',np.min(r_score_CP))\n",
    "\n",
    "print('R-EL mean',np.mean(r_score_EL))\n",
    "print('R-EL max',np.max(r_score_EL))\n",
    "print('R-EL min',np.min(r_score_EL))\n",
    "\n",
    "print('R-LN mean',np.mean(r_score_LN))\n",
    "print('R-LN max',np.max(r_score_LN))\n",
    "print('R-LN min',np.min(r_score_LN))\n",
    "\n",
    "print('R-NE mean',np.mean(r_score_NE))\n",
    "print('R-NE max',np.max(r_score_NE))\n",
    "print('R-NE min',np.min(r_score_NE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 100, 55, 53, 44, 62, 58, 10, 111, 32, 82, 38, 19, 122, 27, 36, 56, 39, 74, 91, 94, 40, 59, 66, 90, 23, 34, 115, 121, 4, 102, 15, 103, 41, 52, 26, 43, 24, 96, 117, 93, 49, 21, 70, 3, 110, 30, 119, 47, 92, 8, 81, 60, 0, 112, 57, 22, 61, 63, 7, 118, 13, 86, 95, 87, 68, 106, 14, 29, 28, 11, 84, 18, 101, 20, 50, 25, 6, 109, 71, 76, 1, 16, 64, 79, 5, 75, 9, 72, 12, 107, 37]\n",
      "['LN', 'NE', 'NE', 'LN', 'CP', 'CP', 'LN', 'NE', 'LN', 'NE', 'NE', 'NE', 'NE', 'EL', 'NE', 'NE', 'NE', 'NE', 'LN', 'EL', 'CP', 'NE', 'LN', 'NE', 'CP', 'NE', 'EL', 'LN', 'LN', 'NE', 'LN', 'NE', 'LN', 'NE', 'NE', 'NE', 'NE', 'NE', 'NE', 'NE', 'NE', 'NE', 'LN', 'NE', 'EL', 'EL', 'NE', 'EL', 'NE', 'LN', 'NE', 'CP', 'NE', 'EL', 'NE', 'NE', 'EL', 'EL', 'NE', 'LN', 'EL', 'LN', 'EL', 'CP', 'NE', 'NE', 'CP', 'LN', 'EL', 'LN', 'NE', 'NE', 'CP', 'EL', 'LN', 'NE', 'NE', 'EL', 'NE', 'NE', 'EL', 'NE', 'NE', 'NE', 'LN', 'NE', 'NE', 'EL', 'CP', 'LN', 'CP', 'LN']\n",
      "92\n",
      "[48, 113, 73, 105, 45, 31, 67, 46, 97, 83, 114, 33, 99, 116, 104, 120, 2, 89, 108, 51, 65, 78, 80, 17, 85, 54, 35, 69, 88, 98, 77]\n",
      "['NE', 'EL', 'NE', 'NE', 'EL', 'NE', 'CP', 'LN', 'NE', 'EL', 'LN', 'NE', 'NE', 'NE', 'NE', 'LN', 'NE', 'NE', 'CP', 'NE', 'LN', 'NE', 'NE', 'NE', 'NE', 'LN', 'NE', 'EL', 'NE', 'CP', 'LN']\n",
      "31\n",
      "CP [67, 108, 98]\n",
      "EP [113, 45, 83, 69]\n",
      "LN [46, 114, 120, 65, 54, 77]\n",
      "NE [48, 73, 105, 31, 97, 33, 99, 116, 104, 2, 89, 51, 78, 80, 17, 85, 35, 88]\n"
     ]
    }
   ],
   "source": [
    "input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2,random_state=1)\n",
    "#79 is a good split\n",
    "#2\n",
    "#5 is ok\n",
    "#6\n",
    "#14\n",
    "#8\n",
    "#15\n",
    "#17\n",
    "#18\n",
    "#20\n",
    "\n",
    "\n",
    "print (input_idx)\n",
    "print (labels_traina)\n",
    "print (len(labels_traina))\n",
    "print (input_test_idx)\n",
    "print (labels_testa)\n",
    "print (len(labels_testa))\n",
    "\n",
    "idx1 = [i for i, x in enumerate(labels_testa) if x=='CP']\n",
    "idx2 = [i for i, x in enumerate(labels_testa) if x=='EL']\n",
    "idx3 = [i for i, x in enumerate(labels_testa) if x=='LN']\n",
    "idx4 = [i for i, x in enumerate(labels_testa) if x=='NE']\n",
    "\n",
    "a=[input_test_idx[i] for i in idx1]\n",
    "print ('CP' , a)\n",
    "a=[input_test_idx[i] for i in idx2]\n",
    "print ('EP' , a)\n",
    "a=[input_test_idx[i] for i in idx3]\n",
    "print ('LN' , a)\n",
    "a=[input_test_idx[i] for i in idx4]\n",
    "print ('NE' , a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#train test split on data selected to be a good split\n",
    "\n",
    "a_score=[0 for i in range(10)]\n",
    "p_score_CP=[0 for i in range(10)]\n",
    "p_score_EL=[0 for i in range(10)]\n",
    "p_score_LN=[0 for i in range(10)]\n",
    "p_score_NE=[0 for i in range(10)]\n",
    "r_score_CP=[0 for i in range(10)]\n",
    "r_score_EL=[0 for i in range(10)]\n",
    "r_score_LN=[0 for i in range(10)]\n",
    "r_score_NE=[0 for i in range(10)]\n",
    "clf_score=[0 for i in range(10)]\n",
    "\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = RandomForestClassifier(max_depth=100)\n",
    "clf4 = MLPClassifier(alpha=0.01,hidden_layer_sizes=(500, ), max_iter=1500)\n",
    "\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('kNN', clf1),('RF', clf3), ('NN', clf4)], voting='soft')#, weights=[2, 1, 2, 1])\n",
    "#79 is a good split\n",
    "#2\n",
    "#5 is ok\n",
    "#6\n",
    "#14\n",
    "#8\n",
    "#15\n",
    "#17\n",
    "#18\n",
    "#20\n",
    "cc=[79,2,5,6,14,8,15,17,18,20]\n",
    "\n",
    "\n",
    "for x in range(10):\n",
    "    print (x)\n",
    "    \n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2,random_state=cc[x])\n",
    "\n",
    "    input_train=np.concatenate([input_HAD[input_idx,:],input_CO1[input_idx,:],input_CO2[input_idx,:],input_ER1[input_idx,:],input_ER2[input_idx,:],input_ER3[input_idx,:],input_KP[input_idx,:]],axis=0)\n",
    "    input_test=np.concatenate([input_HAD[input_test_idx,:],input_CO1[input_test_idx,:],input_CO2[input_test_idx,:],input_ER1[input_test_idx,:],input_ER2[input_test_idx,:],input_ER3[input_test_idx,:],input_KP[input_test_idx,:]],axis=0)\n",
    "\n",
    "    labels_train=labels_traina + labels_traina + labels_traina + labels_traina + labels_traina +labels_traina + labels_traina\n",
    "    labels_test=labels_testa+labels_testa+labels_testa + labels_testa+labels_testa+labels_testa + labels_testa\n",
    "\n",
    "    #choose classifier to be \n",
    "    clf1 = clf1.fit(input_train, labels_train)\n",
    "  #  clf2 = clf2.fit(input_train, labels_train)\n",
    "    clf3 = clf3.fit(input_train, labels_train)\n",
    "    clf4 = clf4.fit(input_train, labels_train)\n",
    "    eclf = eclf.fit(input_train, labels_train)\n",
    "    pred=eclf.predict(input_test)\n",
    "    a_score[x]=accuracy_score(labels_test, pred)\n",
    "    p_score_CP[x]=precision_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    p_score_EL[x]=precision_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    p_score_LN[x]=precision_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    p_score_NE[x]=precision_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    r_score_CP[x]=recall_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    r_score_EL[x]=recall_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    r_score_LN[x]=recall_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    r_score_NE[x]=recall_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    clf_score[x]=cross_val_score(eclf, input_train, labels_train, cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc mean 0.7589861751152074\n",
      "acc max 0.8571428571428571\n",
      "acc min 0.663594470046083\n",
      "CP mean 0.7524188952138136\n",
      "CP max 0.9523809523809523\n",
      "CP min 0.5185185185185185\n",
      "EL mean 0.7412351065250784\n",
      "EL max 0.9166666666666666\n",
      "EL min 0.5714285714285714\n",
      "LN mean 0.7851321657783703\n",
      "LN max 0.9743589743589743\n",
      "LN min 0.4423076923076923\n",
      "NE mean 0.7600559749823935\n",
      "NE max 0.8429752066115702\n",
      "NE min 0.6494845360824743\n",
      "clf mean 0.9706758720930233\n",
      "clf max 0.9798207364341085\n",
      "clf min 0.9658551356589147\n",
      "R-NE mean 0.8006959706959706\n",
      "R-NE max 0.9523809523809523\n",
      "R-NE min 0.6593406593406593\n",
      "R-CP mean 0.6397619047619048\n",
      "R-CP max 0.9523809523809523\n",
      "R-CP min 0.42857142857142855\n",
      "R-EL mean 0.8009183673469387\n",
      "R-EL max 1.0\n",
      "R-EL min 0.6285714285714286\n",
      "R-LN mean 0.7220748299319728\n",
      "R-LN max 0.9387755102040817\n",
      "R-LN min 0.6031746031746031\n",
      "R-NE mean 0.8006959706959706\n",
      "R-NE max 0.9523809523809523\n",
      "R-NE min 0.6593406593406593\n"
     ]
    }
   ],
   "source": [
    "print('acc mean',np.mean(a_score))\n",
    "print('acc max',np.max(a_score))\n",
    "print('acc min',np.min(a_score))\n",
    "\n",
    "print('CP mean',np.mean(p_score_CP))\n",
    "print('CP max',np.max(p_score_CP))\n",
    "print('CP min',np.min(p_score_CP))\n",
    "\n",
    "print('EL mean',np.mean(p_score_EL))\n",
    "print('EL max',np.max(p_score_EL))\n",
    "print('EL min',np.min(p_score_EL))\n",
    "\n",
    "print('LN mean',np.mean(p_score_LN))\n",
    "print('LN max',np.max(p_score_LN))\n",
    "print('LN min',np.min(p_score_LN))\n",
    "\n",
    "print('NE mean',np.mean(p_score_NE))\n",
    "print('NE max',np.max(p_score_NE))\n",
    "print('NE min',np.min(p_score_NE))\n",
    "\n",
    "print('clf mean',np.mean(clf_score))\n",
    "print('clf max',np.max(clf_score))\n",
    "print('clf min',np.min(clf_score))\n",
    "\n",
    "print('R-NE mean',np.mean(r_score_NE))\n",
    "print('R-NE max',np.max(r_score_NE))\n",
    "print('R-NE min',np.min(r_score_NE))\n",
    "\n",
    "print('R-CP mean',np.mean(r_score_CP))\n",
    "print('R-CP max',np.max(r_score_CP))\n",
    "print('R-CP min',np.min(r_score_CP))\n",
    "\n",
    "print('R-EL mean',np.mean(r_score_EL))\n",
    "print('R-EL max',np.max(r_score_EL))\n",
    "print('R-EL min',np.min(r_score_EL))\n",
    "\n",
    "print('R-LN mean',np.mean(r_score_LN))\n",
    "print('R-LN max',np.max(r_score_LN))\n",
    "print('R-LN min',np.min(r_score_LN))\n",
    "\n",
    "print('R-NE mean',np.mean(r_score_NE))\n",
    "print('R-NE max',np.max(r_score_NE))\n",
    "print('R-NE min',np.min(r_score_NE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#train test split on data selected to be a good split: test only one dataset HadISST\n",
    "\n",
    "\n",
    "a_score=[0 for i in range(10)]\n",
    "p_score_CP=[0 for i in range(10)]\n",
    "p_score_EL=[0 for i in range(10)]\n",
    "p_score_LN=[0 for i in range(10)]\n",
    "p_score_NE=[0 for i in range(10)]\n",
    "r_score_CP=[0 for i in range(10)]\n",
    "r_score_EL=[0 for i in range(10)]\n",
    "r_score_LN=[0 for i in range(10)]\n",
    "r_score_NE=[0 for i in range(10)]\n",
    "clf_score=[0 for i in range(10)]\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = RandomForestClassifier(max_depth=100)\n",
    "clf4 = MLPClassifier(alpha=0.01,hidden_layer_sizes=(500, ), max_iter=1500)\n",
    "\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('kNN', clf1),('RF', clf3), ('NN', clf4)], voting='soft')#, weights=[2, 1, 2, 1])\n",
    "\n",
    "#79 is a good split\n",
    "#2\n",
    "#5 is ok\n",
    "#6\n",
    "#14\n",
    "#8\n",
    "#15\n",
    "#17\n",
    "#18\n",
    "#20\n",
    "cc=[79,2,5,6,14,8,15,17,18,20]\n",
    "\n",
    "\n",
    "for x in range(10):\n",
    "    print (x)\n",
    "    \n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2,random_state=cc[x])\n",
    "\n",
    "    input_train=np.concatenate([input_HAD[input_idx,:],input_CO1[input_idx,:],input_CO2[input_idx,:],input_ER1[input_idx,:],input_ER2[input_idx,:],input_ER3[input_idx,:],input_KP[input_idx,:]],axis=0)\n",
    "    input_test=np.concatenate([input_HAD[input_test_idx,:]])#,input_CO1[input_test_idx,:],input_CO2[input_test_idx,:],input_ER1[input_test_idx,:],input_ER2[input_test_idx,:],input_ER3[input_test_idx,:],input_KP[input_test_idx,:]],axis=0)\n",
    "\n",
    "    labels_train=labels_traina + labels_traina + labels_traina + labels_traina + labels_traina +labels_traina + labels_traina\n",
    "    labels_test=labels_testa#+labels_testa+labels_testa + labels_testa+labels_testa+labels_testa + labels_testa\n",
    "\n",
    "    #choose classifier to be \n",
    "    clf1 = clf1.fit(input_train, labels_train)\n",
    "   # clf2 = clf2.fit(input_train, labels_train)\n",
    "    clf3 = clf3.fit(input_train, labels_train)\n",
    "    clf4 = clf4.fit(input_train, labels_train)\n",
    "    eclf = eclf.fit(input_train, labels_train)\n",
    "    pred=eclf.predict(input_test)\n",
    "    a_score[x]=accuracy_score(labels_test, pred)\n",
    "    p_score_CP[x]=precision_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    p_score_EL[x]=precision_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    p_score_LN[x]=precision_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    p_score_NE[x]=precision_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    r_score_CP[x]=recall_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    r_score_EL[x]=recall_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    r_score_LN[x]=recall_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    r_score_NE[x]=recall_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    clf_score[x]=cross_val_score(eclf, input_train, labels_train, cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc mean 0.767741935483871\n",
      "acc max 0.9032258064516129\n",
      "acc min 0.6774193548387096\n",
      "CP mean 0.8416666666666666\n",
      "CP max 1.0\n",
      "CP min 0.5\n",
      "EL mean 0.8405555555555557\n",
      "EL max 1.0\n",
      "EL min 0.5555555555555556\n",
      "LN mean 0.7692857142857144\n",
      "LN max 1.0\n",
      "LN min 0.42857142857142855\n",
      "NE mean 0.7391223108676669\n",
      "NE max 0.8333333333333334\n",
      "NE min 0.6153846153846154\n",
      "clf mean 0.9709847383720931\n",
      "clf max 0.984484011627907\n",
      "clf min 0.9643047480620155\n",
      "R-NE mean 0.8442628205128205\n",
      "R-NE max 1.0\n",
      "R-NE min 0.6666666666666666\n",
      "R-CP mean 0.5050000000000001\n",
      "R-CP max 1.0\n",
      "R-CP min 0.25\n",
      "R-EL mean 0.9040476190476191\n",
      "R-EL max 1.0\n",
      "R-EL min 0.75\n",
      "R-LN mean 0.6580952380952381\n",
      "R-LN max 0.8571428571428571\n",
      "R-LN min 0.5\n",
      "R-NE mean 0.8442628205128205\n",
      "R-NE max 1.0\n",
      "R-NE min 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print('acc mean',np.mean(a_score))\n",
    "print('acc max',np.max(a_score))\n",
    "print('acc min',np.min(a_score))\n",
    "\n",
    "print('CP mean',np.mean(p_score_CP))\n",
    "print('CP max',np.max(p_score_CP))\n",
    "print('CP min',np.min(p_score_CP))\n",
    "\n",
    "print('EL mean',np.mean(p_score_EL))\n",
    "print('EL max',np.max(p_score_EL))\n",
    "print('EL min',np.min(p_score_EL))\n",
    "\n",
    "print('LN mean',np.mean(p_score_LN))\n",
    "print('LN max',np.max(p_score_LN))\n",
    "print('LN min',np.min(p_score_LN))\n",
    "\n",
    "print('NE mean',np.mean(p_score_NE))\n",
    "print('NE max',np.max(p_score_NE))\n",
    "print('NE min',np.min(p_score_NE))\n",
    "\n",
    "print('clf mean',np.mean(clf_score))\n",
    "print('clf max',np.max(clf_score))\n",
    "print('clf min',np.min(clf_score))\n",
    "\n",
    "print('R-NE mean',np.mean(r_score_NE))\n",
    "print('R-NE max',np.max(r_score_NE))\n",
    "print('R-NE min',np.min(r_score_NE))\n",
    "\n",
    "print('R-CP mean',np.mean(r_score_CP))\n",
    "print('R-CP max',np.max(r_score_CP))\n",
    "print('R-CP min',np.min(r_score_CP))\n",
    "\n",
    "print('R-EL mean',np.mean(r_score_EL))\n",
    "print('R-EL max',np.max(r_score_EL))\n",
    "print('R-EL min',np.min(r_score_EL))\n",
    "\n",
    "print('R-LN mean',np.mean(r_score_LN))\n",
    "print('R-LN max',np.max(r_score_LN))\n",
    "print('R-LN min',np.min(r_score_LN))\n",
    "\n",
    "print('R-NE mean',np.mean(r_score_NE))\n",
    "print('R-NE max',np.max(r_score_NE))\n",
    "print('R-NE min',np.min(r_score_NE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#train test split on data selected to be a good split: train and test only one dataset HadISST\n",
    "\n",
    "\n",
    "a_score=[0 for i in range(10)]\n",
    "p_score_CP=[0 for i in range(10)]\n",
    "p_score_EL=[0 for i in range(10)]\n",
    "p_score_LN=[0 for i in range(10)]\n",
    "p_score_NE=[0 for i in range(10)]\n",
    "r_score_CP=[0 for i in range(10)]\n",
    "r_score_EL=[0 for i in range(10)]\n",
    "r_score_LN=[0 for i in range(10)]\n",
    "r_score_NE=[0 for i in range(10)]\n",
    "clf_score=[0 for i in range(10)]\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = RandomForestClassifier(max_depth=100)\n",
    "clf4 = MLPClassifier(alpha=0.01,hidden_layer_sizes=(500, ), max_iter=1500)\n",
    "\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('kNN', clf1),('RF', clf3), ('NN', clf4)], voting='soft')#, weights=[2, 1, 2, 1])\n",
    "#79 is a good split\n",
    "#2\n",
    "#5 is ok\n",
    "#6\n",
    "#14\n",
    "#8\n",
    "#15\n",
    "#17\n",
    "#18\n",
    "#20\n",
    "cc=[79,2,5,6,14,8,15,17,18,20]\n",
    "\n",
    "\n",
    "for x in range(10):\n",
    "    print (x)\n",
    "    \n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2,random_state=cc[x])\n",
    "\n",
    "    input_train=np.concatenate([input_HAD[input_idx,:]])#,input_CO1[input_idx,:],input_CO2[input_idx,:],input_ER1[input_idx,:],input_ER2[input_idx,:],input_ER3[input_idx,:],input_KP[input_idx,:]],axis=0)\n",
    "    input_test=np.concatenate([input_HAD[input_test_idx,:]])#,input_CO1[input_test_idx,:],input_CO2[input_test_idx,:],input_ER1[input_test_idx,:],input_ER2[input_test_idx,:],input_ER3[input_test_idx,:],input_KP[input_test_idx,:]],axis=0)\n",
    "\n",
    "    labels_train=labels_traina# + labels_traina + labels_traina + labels_traina + labels_traina +labels_traina + labels_traina\n",
    "    labels_test=labels_testa#+labels_testa+labels_testa + labels_testa+labels_testa+labels_testa + labels_testa\n",
    "\n",
    "    #choose classifier to be \n",
    "    clf1 = clf1.fit(input_train, labels_train)\n",
    "   # clf2 = clf2.fit(input_train, labels_train)\n",
    "    clf3 = clf3.fit(input_train, labels_train)\n",
    "    clf4 = clf4.fit(input_train, labels_train)\n",
    "    eclf = eclf.fit(input_train, labels_train)\n",
    "    pred=eclf.predict(input_test)\n",
    "    a_score[x]=accuracy_score(labels_test, pred)\n",
    "    p_score_CP[x]=precision_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    p_score_EL[x]=precision_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    p_score_LN[x]=precision_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    p_score_NE[x]=precision_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    r_score_CP[x]=recall_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    r_score_EL[x]=recall_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    r_score_LN[x]=recall_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    r_score_NE[x]=recall_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    clf_score[x]=cross_val_score(eclf, input_train, labels_train, cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc mean 0.735483870967742\n",
      "acc max 0.9032258064516129\n",
      "acc min 0.5806451612903226\n",
      "CP mean 0.6516666666666666\n",
      "CP max 1.0\n",
      "CP min 0.25\n",
      "EL mean 0.811010101010101\n",
      "EL max 1.0\n",
      "EL min 0.45454545454545453\n",
      "LN mean 0.8038095238095238\n",
      "LN max 1.0\n",
      "LN min 0.5\n",
      "NE mean 0.7323699756555793\n",
      "NE max 0.8421052631578947\n",
      "NE min 0.5384615384615384\n",
      "clf mean 0.7346783625730995\n",
      "clf max 0.7713450292397661\n",
      "clf min 0.6619883040935672\n",
      "R-NE mean 0.8207371794871795\n",
      "R-NE max 1.0\n",
      "R-NE min 0.5833333333333334\n",
      "R-CP mean 0.5\n",
      "R-CP max 1.0\n",
      "R-CP min 0.25\n",
      "R-EL mean 0.7988095238095239\n",
      "R-EL max 1.0\n",
      "R-EL min 0.5714285714285714\n",
      "R-LN mean 0.6593650793650794\n",
      "R-LN max 0.8571428571428571\n",
      "R-LN min 0.5\n",
      "R-NE mean 0.8207371794871795\n",
      "R-NE max 1.0\n",
      "R-NE min 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "print('acc mean',np.mean(a_score))\n",
    "print('acc max',np.max(a_score))\n",
    "print('acc min',np.min(a_score))\n",
    "\n",
    "print('CP mean',np.mean(p_score_CP))\n",
    "print('CP max',np.max(p_score_CP))\n",
    "print('CP min',np.min(p_score_CP))\n",
    "\n",
    "print('EL mean',np.mean(p_score_EL))\n",
    "print('EL max',np.max(p_score_EL))\n",
    "print('EL min',np.min(p_score_EL))\n",
    "\n",
    "print('LN mean',np.mean(p_score_LN))\n",
    "print('LN max',np.max(p_score_LN))\n",
    "print('LN min',np.min(p_score_LN))\n",
    "\n",
    "print('NE mean',np.mean(p_score_NE))\n",
    "print('NE max',np.max(p_score_NE))\n",
    "print('NE min',np.min(p_score_NE))\n",
    "\n",
    "print('clf mean',np.mean(clf_score))\n",
    "print('clf max',np.max(clf_score))\n",
    "print('clf min',np.min(clf_score))\n",
    "\n",
    "print('R-NE mean',np.mean(r_score_NE))\n",
    "print('R-NE max',np.max(r_score_NE))\n",
    "print('R-NE min',np.min(r_score_NE))\n",
    "\n",
    "print('R-CP mean',np.mean(r_score_CP))\n",
    "print('R-CP max',np.max(r_score_CP))\n",
    "print('R-CP min',np.min(r_score_CP))\n",
    "\n",
    "print('R-EL mean',np.mean(r_score_EL))\n",
    "print('R-EL max',np.max(r_score_EL))\n",
    "print('R-EL min',np.min(r_score_EL))\n",
    "\n",
    "print('R-LN mean',np.mean(r_score_LN))\n",
    "print('R-LN max',np.max(r_score_LN))\n",
    "print('R-LN min',np.min(r_score_LN))\n",
    "\n",
    "print('R-NE mean',np.mean(r_score_NE))\n",
    "print('R-NE max',np.max(r_score_NE))\n",
    "print('R-NE min',np.min(r_score_NE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
