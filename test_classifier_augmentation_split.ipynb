{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook tests the data by spliting so the same event cannot be included in both the training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import build-in\n",
    "import numpy as np\n",
    "\n",
    "# import local\n",
    "import utility_classification as ut_cla\n",
    "import labels_create_ENSO as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up path to data\n",
    "path = '/home/nicola/Documents/classification_clean/data/regions/'\n",
    "\n",
    "#create dictionary with all input data\n",
    "dict_data_struc ={\n",
    "        1:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        2:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        3:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        4:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        5:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        6:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' :42,\n",
    "           'firstmon' :10},\n",
    "        7:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        8:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        9:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        10:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10}, \n",
    "        11:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        12:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        13:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        14:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        15:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10}, \n",
    "        16:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :10},\n",
    "        17:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :10},\n",
    "        18:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :10},\n",
    "        19:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :10},\n",
    "        20:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :10}, \n",
    "        21:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :10},\n",
    "        22:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :10},\n",
    "        23:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :10},\n",
    "        24:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :10},\n",
    "        25:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :10},       \n",
    "        26:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :10},\n",
    "        27:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :10},\n",
    "        28:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :10},\n",
    "        29:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :10},\n",
    "        30:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :10},\n",
    "        31:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :10},\n",
    "        32:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :10},\n",
    "        33:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :10},\n",
    "        34:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :10},\n",
    "        35:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :10}\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process all data\n",
    "result = ut_cla.preprocess_from_dict(dict_data_struc, path, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the data for each of the three long timeseries\n",
    "input_ER1=np.concatenate([result[1],result[2],result[3],result[4],result[5]],axis=1)\n",
    "input_ER2=np.concatenate([result[6],result[7],result[8],result[9],result[10]],axis=1)\n",
    "input_ER3=np.concatenate([result[11],result[12],result[13],result[14],result[15]],axis=1)\n",
    "input_CO1=np.concatenate([result[16],result[17],result[18],result[19],result[20]],axis=1)\n",
    "input_CO2=np.concatenate([result[21],result[22],result[23],result[24],result[25]],axis=1)\n",
    "input_KP=np.concatenate([result[26],result[27],result[28],result[29],result[30]],axis=1)\n",
    "input_HAD=np.concatenate([result[31],result[32],result[33],result[34],result[35]],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create labels\n",
    "labels_train,labels_test=labels.create_labels()\n",
    "labels_test2=labels_test\n",
    "labels_data=[i for i in range(123)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the machine learning tools\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#Ensemble class scores: random train/test\n",
    "\n",
    "a_score=[0 for i in range(10)]\n",
    "p_score_CP=[0 for i in range(10)]\n",
    "p_score_EL=[0 for i in range(10)]\n",
    "p_score_LN=[0 for i in range(10)]\n",
    "p_score_NE=[0 for i in range(10)]\n",
    "clf_score=[0 for i in range(10)]\n",
    "\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = RandomForestClassifier(n_estimators=500, max_depth=500)\n",
    "clf4 = MLPClassifier(hidden_layer_sizes=(500, ), max_iter=900)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('kNN', clf1),('RF', clf3), ('NN', clf4)], voting='soft')#, weights=[2, 1, 2, 1])\n",
    "\n",
    "\n",
    "for x in range(0, 10):\n",
    "    print(x)\n",
    "\n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2)\n",
    "\n",
    "    input_train=np.concatenate([input_HAD[input_idx,:],input_CO1[input_idx,:],input_CO2[input_idx,:],input_ER1[input_idx,:],input_ER2[input_idx,:],input_ER3[input_idx,:],input_KP[input_idx,:]],axis=0)\n",
    "    input_test=np.concatenate([input_HAD[input_test_idx,:],input_CO1[input_test_idx,:],input_CO2[input_test_idx,:],input_ER1[input_test_idx,:],input_ER2[input_test_idx,:],input_ER3[input_test_idx,:],input_KP[input_test_idx,:]],axis=0)\n",
    "\n",
    "    labels_train=labels_traina + labels_traina + labels_traina + labels_traina + labels_traina +labels_traina + labels_traina\n",
    "    labels_test=labels_testa+labels_testa+labels_testa + labels_testa+labels_testa+labels_testa + labels_testa\n",
    "\n",
    "    #choose classifier to be \n",
    "    clf1 = clf1.fit(input_train, labels_train)\n",
    "   # clf2 = clf2.fit(input_train, labels_train)\n",
    "    clf3 = clf3.fit(input_train, labels_train)\n",
    "    clf4 = clf4.fit(input_train, labels_train)\n",
    "    eclf = eclf.fit(input_train, labels_train)\n",
    "    pred=eclf.predict(input_test)\n",
    "    a_score[x]=accuracy_score(labels_test, pred)\n",
    "    p_score_CP[x]=precision_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    p_score_EL[x]=precision_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    p_score_LN[x]=precision_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    p_score_NE[x]=precision_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    clf_score[x]=cross_val_score(eclf, input_train, labels_train, cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc mean 0.7373271889400921\n",
      "acc max 0.8202764976958525\n",
      "acc min 0.6497695852534562\n",
      "CP mean 0.27740912337097645\n",
      "CP max 0.5294117647058824\n",
      "CP min 0.07692307692307693\n",
      "EL mean 0.55358250460497\n",
      "EL max 0.7857142857142857\n",
      "EL min 0.22727272727272727\n",
      "LN mean 0.8326389661036648\n",
      "LN max 0.9622641509433962\n",
      "LN min 0.7\n",
      "NE mean 0.8376570259281031\n",
      "NE max 0.9310344827586207\n",
      "NE min 0.6140350877192983\n",
      "clf mean 0.941500726744186\n",
      "clf max 0.9596656976744186\n",
      "clf min 0.9255087209302324\n"
     ]
    }
   ],
   "source": [
    "print('acc mean',np.mean(a_score))\n",
    "print('acc max',np.max(a_score))\n",
    "print('acc min',np.min(a_score))\n",
    "\n",
    "print('CP mean',np.mean(p_score_CP))\n",
    "print('CP max',np.max(p_score_CP))\n",
    "print('CP min',np.min(p_score_CP))\n",
    "\n",
    "print('EL mean',np.mean(p_score_EL))\n",
    "print('EL max',np.max(p_score_EL))\n",
    "print('EL min',np.min(p_score_EL))\n",
    "\n",
    "print('LN mean',np.mean(p_score_LN))\n",
    "print('LN max',np.max(p_score_LN))\n",
    "print('LN min',np.min(p_score_LN))\n",
    "\n",
    "print('NE mean',np.mean(p_score_NE))\n",
    "print('NE max',np.max(p_score_NE))\n",
    "print('NE min',np.min(p_score_NE))\n",
    "\n",
    "print('clf mean',np.mean(clf_score))\n",
    "print('clf max',np.max(clf_score))\n",
    "print('clf min',np.min(clf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 100, 55, 53, 44, 62, 58, 10, 111, 32, 82, 38, 19, 122, 27, 36, 56, 39, 74, 91, 94, 40, 59, 66, 90, 23, 34, 115, 121, 4, 102, 15, 103, 41, 52, 26, 43, 24, 96, 117, 93, 49, 21, 70, 3, 110, 30, 119, 47, 92, 8, 81, 60, 0, 112, 57, 22, 61, 63, 7, 118, 13, 86, 95, 87, 68, 106, 14, 29, 28, 11, 84, 18, 101, 20, 50, 25, 6, 109, 71, 76, 1, 16, 64, 79, 5, 75, 9, 72, 12, 107, 37]\n",
      "['LN', 'NE', 'NE', 'LN', 'CP', 'CP', 'LN', 'NE', 'LN', 'NE', 'NE', 'NE', 'NE', 'EL', 'NE', 'NE', 'NE', 'NE', 'LN', 'EL', 'CP', 'NE', 'LN', 'NE', 'CP', 'NE', 'EL', 'LN', 'LN', 'NE', 'LN', 'NE', 'LN', 'NE', 'NE', 'NE', 'NE', 'NE', 'NE', 'NE', 'NE', 'NE', 'LN', 'NE', 'EL', 'EL', 'NE', 'EL', 'NE', 'LN', 'NE', 'CP', 'NE', 'EL', 'NE', 'NE', 'EL', 'EL', 'NE', 'LN', 'EL', 'LN', 'EL', 'CP', 'NE', 'NE', 'CP', 'LN', 'EL', 'LN', 'NE', 'NE', 'CP', 'EL', 'LN', 'NE', 'NE', 'EL', 'NE', 'NE', 'EL', 'NE', 'NE', 'NE', 'LN', 'NE', 'NE', 'EL', 'CP', 'LN', 'CP', 'LN']\n",
      "92\n",
      "[48, 113, 73, 105, 45, 31, 67, 46, 97, 83, 114, 33, 99, 116, 104, 120, 2, 89, 108, 51, 65, 78, 80, 17, 85, 54, 35, 69, 88, 98, 77]\n",
      "['NE', 'EL', 'NE', 'NE', 'EL', 'NE', 'CP', 'LN', 'NE', 'EL', 'LN', 'NE', 'NE', 'NE', 'NE', 'LN', 'NE', 'NE', 'CP', 'NE', 'LN', 'NE', 'NE', 'NE', 'NE', 'LN', 'NE', 'EL', 'NE', 'CP', 'LN']\n",
      "31\n",
      "CP [67, 108, 98]\n",
      "EP [113, 45, 83, 69]\n",
      "LN [46, 114, 120, 65, 54, 77]\n",
      "NE [48, 73, 105, 31, 97, 33, 99, 116, 104, 2, 89, 51, 78, 80, 17, 85, 35, 88]\n"
     ]
    }
   ],
   "source": [
    "input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2,random_state=1)\n",
    "#79 is a good split\n",
    "#2\n",
    "#5 is ok\n",
    "#6\n",
    "#14\n",
    "#8\n",
    "#15\n",
    "#17\n",
    "#18\n",
    "#20\n",
    "\n",
    "\n",
    "print (input_idx)\n",
    "print (labels_traina)\n",
    "print (len(labels_traina))\n",
    "print (input_test_idx)\n",
    "print (labels_testa)\n",
    "print (len(labels_testa))\n",
    "\n",
    "idx1 = [i for i, x in enumerate(labels_testa) if x=='CP']\n",
    "idx2 = [i for i, x in enumerate(labels_testa) if x=='EL']\n",
    "idx3 = [i for i, x in enumerate(labels_testa) if x=='LN']\n",
    "idx4 = [i for i, x in enumerate(labels_testa) if x=='NE']\n",
    "\n",
    "a=[input_test_idx[i] for i in idx1]\n",
    "print ('CP' , a)\n",
    "a=[input_test_idx[i] for i in idx2]\n",
    "print ('EP' , a)\n",
    "a=[input_test_idx[i] for i in idx3]\n",
    "print ('LN' , a)\n",
    "a=[input_test_idx[i] for i in idx4]\n",
    "print ('NE' , a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#train test split on data selected to be a good split\n",
    "\n",
    "a_score=[0 for i in range(10)]\n",
    "p_score_CP=[0 for i in range(10)]\n",
    "p_score_EL=[0 for i in range(10)]\n",
    "p_score_LN=[0 for i in range(10)]\n",
    "p_score_NE=[0 for i in range(10)]\n",
    "clf_score=[0 for i in range(10)]\n",
    "\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = RandomForestClassifier(n_estimators=500, max_depth=500)\n",
    "clf4 = MLPClassifier(hidden_layer_sizes=(500, ), max_iter=900)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('kNN', clf1),('RF', clf3), ('NN', clf4)], voting='soft')#, weights=[2, 1, 2, 1])\n",
    "#79 is a good split\n",
    "#2\n",
    "#5 is ok\n",
    "#6\n",
    "#14\n",
    "#8\n",
    "#15\n",
    "#17\n",
    "#18\n",
    "#20\n",
    "cc=[79,2,5,6,14,8,15,17,18,20]\n",
    "\n",
    "\n",
    "for x in range(10):\n",
    "    print (x)\n",
    "    \n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2,random_state=cc[x])\n",
    "\n",
    "    input_train=np.concatenate([input_HAD[input_idx,:],input_CO1[input_idx,:],input_CO2[input_idx,:],input_ER1[input_idx,:],input_ER2[input_idx,:],input_ER3[input_idx,:],input_KP[input_idx,:]],axis=0)\n",
    "    input_test=np.concatenate([input_HAD[input_test_idx,:],input_CO1[input_test_idx,:],input_CO2[input_test_idx,:],input_ER1[input_test_idx,:],input_ER2[input_test_idx,:],input_ER3[input_test_idx,:],input_KP[input_test_idx,:]],axis=0)\n",
    "\n",
    "    labels_train=labels_traina + labels_traina + labels_traina + labels_traina + labels_traina +labels_traina + labels_traina\n",
    "    labels_test=labels_testa+labels_testa+labels_testa + labels_testa+labels_testa+labels_testa + labels_testa\n",
    "\n",
    "    #choose classifier to be \n",
    "    clf1 = clf1.fit(input_train, labels_train)\n",
    "  #  clf2 = clf2.fit(input_train, labels_train)\n",
    "    clf3 = clf3.fit(input_train, labels_train)\n",
    "    clf4 = clf4.fit(input_train, labels_train)\n",
    "    eclf = eclf.fit(input_train, labels_train)\n",
    "    pred=eclf.predict(input_test)\n",
    "    a_score[x]=accuracy_score(labels_test, pred)\n",
    "    p_score_CP[x]=precision_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    p_score_EL[x]=precision_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    p_score_LN[x]=precision_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    p_score_NE[x]=precision_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    clf_score[x]=cross_val_score(eclf, input_train, labels_train, cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc mean 0.7341013824884792\n",
      "acc max 0.8064516129032258\n",
      "acc min 0.6866359447004609\n",
      "CP mean 0.49982468441842187\n",
      "CP max 0.7692307692307693\n",
      "CP min 0.23529411764705882\n",
      "EL mean 0.6694150767859393\n",
      "EL max 0.972972972972973\n",
      "EL min 0.5555555555555556\n",
      "LN mean 0.8204383770925361\n",
      "LN max 1.0\n",
      "LN min 0.5434782608695652\n",
      "NE mean 0.7654195055800033\n",
      "NE max 0.8785046728971962\n",
      "NE min 0.65625\n",
      "clf mean 0.9377725290697674\n",
      "clf max 0.9550024224806201\n",
      "clf min 0.9286094961240309\n"
     ]
    }
   ],
   "source": [
    "print('acc mean',np.mean(a_score))\n",
    "print('acc max',np.max(a_score))\n",
    "print('acc min',np.min(a_score))\n",
    "\n",
    "print('CP mean',np.mean(p_score_CP))\n",
    "print('CP max',np.max(p_score_CP))\n",
    "print('CP min',np.min(p_score_CP))\n",
    "\n",
    "print('EL mean',np.mean(p_score_EL))\n",
    "print('EL max',np.max(p_score_EL))\n",
    "print('EL min',np.min(p_score_EL))\n",
    "\n",
    "print('LN mean',np.mean(p_score_LN))\n",
    "print('LN max',np.max(p_score_LN))\n",
    "print('LN min',np.min(p_score_LN))\n",
    "\n",
    "print('NE mean',np.mean(p_score_NE))\n",
    "print('NE max',np.max(p_score_NE))\n",
    "print('NE min',np.min(p_score_NE))\n",
    "\n",
    "print('clf mean',np.mean(clf_score))\n",
    "print('clf max',np.max(clf_score))\n",
    "print('clf min',np.min(clf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#train test split on data selected to be a good split: test only one dataset HadISST\n",
    "\n",
    "\n",
    "a_score=[0 for i in range(10)]\n",
    "p_score_CP=[0 for i in range(10)]\n",
    "p_score_EL=[0 for i in range(10)]\n",
    "p_score_LN=[0 for i in range(10)]\n",
    "p_score_NE=[0 for i in range(10)]\n",
    "clf_score=[0 for i in range(10)]\n",
    "\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = RandomForestClassifier(n_estimators=500, max_depth=500)\n",
    "clf4 = MLPClassifier(hidden_layer_sizes=(500, ), max_iter=900)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('kNN', clf1),('RF', clf3), ('NN', clf4)], voting='soft')#, weights=[2, 1, 2, 1])\n",
    "\n",
    "#79 is a good split\n",
    "#2\n",
    "#5 is ok\n",
    "#6\n",
    "#14\n",
    "#8\n",
    "#15\n",
    "#17\n",
    "#18\n",
    "#20\n",
    "cc=[79,2,5,6,14,8,15,17,18,20]\n",
    "\n",
    "\n",
    "for x in range(10):\n",
    "    print (x)\n",
    "    \n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2,random_state=cc[x])\n",
    "\n",
    "    input_train=np.concatenate([input_HAD[input_idx,:],input_CO1[input_idx,:],input_CO2[input_idx,:],input_ER1[input_idx,:],input_ER2[input_idx,:],input_ER3[input_idx,:],input_KP[input_idx,:]],axis=0)\n",
    "    input_test=np.concatenate([input_HAD[input_test_idx,:]])#,input_CO1[input_test_idx,:],input_CO2[input_test_idx,:],input_ER1[input_test_idx,:],input_ER2[input_test_idx,:],input_ER3[input_test_idx,:],input_KP[input_test_idx,:]],axis=0)\n",
    "\n",
    "    labels_train=labels_traina + labels_traina + labels_traina + labels_traina + labels_traina +labels_traina + labels_traina\n",
    "    labels_test=labels_testa#+labels_testa+labels_testa + labels_testa+labels_testa+labels_testa + labels_testa\n",
    "\n",
    "    #choose classifier to be \n",
    "    clf1 = clf1.fit(input_train, labels_train)\n",
    "   # clf2 = clf2.fit(input_train, labels_train)\n",
    "    clf3 = clf3.fit(input_train, labels_train)\n",
    "    clf4 = clf4.fit(input_train, labels_train)\n",
    "    eclf = eclf.fit(input_train, labels_train)\n",
    "    pred=eclf.predict(input_test)\n",
    "    a_score[x]=accuracy_score(labels_test, pred)\n",
    "    p_score_CP[x]=precision_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    p_score_EL[x]=precision_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    p_score_LN[x]=precision_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    p_score_NE[x]=precision_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    clf_score[x]=cross_val_score(eclf, input_train, labels_train, cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc mean 0.7387096774193549\n",
      "acc max 0.8709677419354839\n",
      "acc min 0.5806451612903226\n",
      "CP mean 0.5866666666666667\n",
      "CP max 1.0\n",
      "CP min 0.0\n",
      "EL mean 0.7696428571428571\n",
      "EL max 1.0\n",
      "EL min 0.5714285714285714\n",
      "LN mean 0.8123809523809523\n",
      "LN max 1.0\n",
      "LN min 0.5\n",
      "NE mean 0.7373179271708683\n",
      "NE max 0.875\n",
      "NE min 0.5333333333333333\n",
      "clf mean 0.9374612403100775\n",
      "clf max 0.9534520348837209\n",
      "clf min 0.9270591085271317\n"
     ]
    }
   ],
   "source": [
    "print('acc mean',np.mean(a_score))\n",
    "print('acc max',np.max(a_score))\n",
    "print('acc min',np.min(a_score))\n",
    "\n",
    "print('CP mean',np.mean(p_score_CP))\n",
    "print('CP max',np.max(p_score_CP))\n",
    "print('CP min',np.min(p_score_CP))\n",
    "\n",
    "print('EL mean',np.mean(p_score_EL))\n",
    "print('EL max',np.max(p_score_EL))\n",
    "print('EL min',np.min(p_score_EL))\n",
    "\n",
    "print('LN mean',np.mean(p_score_LN))\n",
    "print('LN max',np.max(p_score_LN))\n",
    "print('LN min',np.min(p_score_LN))\n",
    "\n",
    "print('NE mean',np.mean(p_score_NE))\n",
    "print('NE max',np.max(p_score_NE))\n",
    "print('NE min',np.min(p_score_NE))\n",
    "\n",
    "print('clf mean',np.mean(clf_score))\n",
    "print('clf max',np.max(clf_score))\n",
    "print('clf min',np.min(clf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#train test split on data selected to be a good split: train and test only one dataset HadISST\n",
    "\n",
    "\n",
    "a_score=[0 for i in range(10)]\n",
    "p_score_CP=[0 for i in range(10)]\n",
    "p_score_EL=[0 for i in range(10)]\n",
    "p_score_LN=[0 for i in range(10)]\n",
    "p_score_NE=[0 for i in range(10)]\n",
    "clf_score=[0 for i in range(10)]\n",
    "\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = RandomForestClassifier(n_estimators=500, max_depth=500)\n",
    "clf4 = MLPClassifier(hidden_layer_sizes=(500, ), max_iter=900)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('kNN', clf1),('RF', clf3), ('NN', clf4)], voting='soft')#, weights=[2, 1, 2, 1])\n",
    "#79 is a good split\n",
    "#2\n",
    "#5 is ok\n",
    "#6\n",
    "#14\n",
    "#8\n",
    "#15\n",
    "#17\n",
    "#18\n",
    "#20\n",
    "cc=[79,2,5,6,14,8,15,17,18,20]\n",
    "\n",
    "\n",
    "for x in range(10):\n",
    "    print (x)\n",
    "    \n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2,random_state=cc[x])\n",
    "\n",
    "    input_train=np.concatenate([input_HAD[input_idx,:]])#,input_CO1[input_idx,:],input_CO2[input_idx,:],input_ER1[input_idx,:],input_ER2[input_idx,:],input_ER3[input_idx,:],input_KP[input_idx,:]],axis=0)\n",
    "    input_test=np.concatenate([input_HAD[input_test_idx,:]])#,input_CO1[input_test_idx,:],input_CO2[input_test_idx,:],input_ER1[input_test_idx,:],input_ER2[input_test_idx,:],input_ER3[input_test_idx,:],input_KP[input_test_idx,:]],axis=0)\n",
    "\n",
    "    labels_train=labels_traina# + labels_traina + labels_traina + labels_traina + labels_traina +labels_traina + labels_traina\n",
    "    labels_test=labels_testa#+labels_testa+labels_testa + labels_testa+labels_testa+labels_testa + labels_testa\n",
    "\n",
    "    #choose classifier to be \n",
    "    clf1 = clf1.fit(input_train, labels_train)\n",
    "   # clf2 = clf2.fit(input_train, labels_train)\n",
    "    clf3 = clf3.fit(input_train, labels_train)\n",
    "    clf4 = clf4.fit(input_train, labels_train)\n",
    "    eclf = eclf.fit(input_train, labels_train)\n",
    "    pred=eclf.predict(input_test)\n",
    "    a_score[x]=accuracy_score(labels_test, pred)\n",
    "    p_score_CP[x]=precision_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    p_score_EL[x]=precision_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    p_score_LN[x]=precision_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    p_score_NE[x]=precision_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    clf_score[x]=cross_val_score(eclf, input_train, labels_train, cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc mean 0.7161290322580646\n",
      "acc max 0.8387096774193549\n",
      "acc min 0.5806451612903226\n",
      "CP mean 0.45999999999999996\n",
      "CP max 0.6666666666666666\n",
      "CP min 0.0\n",
      "EL mean 0.7563095238095239\n",
      "EL max 1.0\n",
      "EL min 0.5714285714285714\n",
      "LN mean 0.7888095238095238\n",
      "LN max 1.0\n",
      "LN min 0.5\n",
      "NE mean 0.7294274761186527\n",
      "NE max 0.8461538461538461\n",
      "NE min 0.5625\n",
      "clf mean 0.716140350877193\n",
      "clf max 0.7614035087719297\n",
      "clf min 0.6830409356725144\n"
     ]
    }
   ],
   "source": [
    "print('acc mean',np.mean(a_score))\n",
    "print('acc max',np.max(a_score))\n",
    "print('acc min',np.min(a_score))\n",
    "\n",
    "print('CP mean',np.mean(p_score_CP))\n",
    "print('CP max',np.max(p_score_CP))\n",
    "print('CP min',np.min(p_score_CP))\n",
    "\n",
    "print('EL mean',np.mean(p_score_EL))\n",
    "print('EL max',np.max(p_score_EL))\n",
    "print('EL min',np.min(p_score_EL))\n",
    "\n",
    "print('LN mean',np.mean(p_score_LN))\n",
    "print('LN max',np.max(p_score_LN))\n",
    "print('LN min',np.min(p_score_LN))\n",
    "\n",
    "print('NE mean',np.mean(p_score_NE))\n",
    "print('NE max',np.max(p_score_NE))\n",
    "print('NE min',np.min(p_score_NE))\n",
    "\n",
    "print('clf mean',np.mean(clf_score))\n",
    "print('clf max',np.max(clf_score))\n",
    "print('clf min',np.min(clf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
