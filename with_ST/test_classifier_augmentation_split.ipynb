{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook tests the data by spliting so the same event cannot be included in both the training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import build-in\n",
    "import numpy as np\n",
    "\n",
    "# import local\n",
    "import utility_classification as ut_cla\n",
    "import labels_create_ENSO_ST as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up path to data\n",
    "path = '/home/nicola/Documents/classification_clean/data/regions/'\n",
    "\n",
    "#create dictionary with all input data\n",
    "dict_data_struc ={\n",
    "        1:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        2:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        3:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        4:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        5:{'filename' : 'ERSSTv3b.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        6:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' :42,\n",
    "           'firstmon' :10},\n",
    "        7:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        8:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        9:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        10:{'filename' : 'ERSSTv4.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10}, \n",
    "        11:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        12:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        13:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        14:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10},\n",
    "        15:{'filename' : 'ERSSTv5.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 42,\n",
    "           'firstmon' :10}, \n",
    "        16:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :10},\n",
    "        17:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :10},\n",
    "        18:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :10},\n",
    "        19:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :10},\n",
    "        20:{'filename' : 'COBESST2.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 46,\n",
    "           'firstmon' :10}, \n",
    "        21:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :10},\n",
    "        22:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :10},\n",
    "        23:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :10},\n",
    "        24:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :10},\n",
    "        25:{'filename' : 'COBEv1.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 5,\n",
    "           'firstmon' :10},       \n",
    "        26:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :10},\n",
    "        27:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :10},\n",
    "        28:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :10},\n",
    "        29:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :10},\n",
    "        30:{'filename' : 'kaplan_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 40,\n",
    "           'firstmon' :10},\n",
    "        31:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino3W.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :10},\n",
    "        32:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino3E.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :10},\n",
    "        33:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino4W.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :10},\n",
    "        34:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino4E.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :10},\n",
    "        35:{'filename' : 'HadISST_sst.nc_regrid.nc_detrended.nc_deseason.nc_nino12.nc',\n",
    "           'crop' : 26,\n",
    "           'firstmon' :10}\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process all data\n",
    "result = ut_cla.preprocess_from_dict(dict_data_struc, path, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the data for each of the three long timeseries\n",
    "input_ER1=np.concatenate([result[1],result[2],result[3],result[4],result[5]],axis=1)\n",
    "input_ER2=np.concatenate([result[6],result[7],result[8],result[9],result[10]],axis=1)\n",
    "input_ER3=np.concatenate([result[11],result[12],result[13],result[14],result[15]],axis=1)\n",
    "input_CO1=np.concatenate([result[16],result[17],result[18],result[19],result[20]],axis=1)\n",
    "input_CO2=np.concatenate([result[21],result[22],result[23],result[24],result[25]],axis=1)\n",
    "input_KP=np.concatenate([result[26],result[27],result[28],result[29],result[30]],axis=1)\n",
    "input_HAD=np.concatenate([result[31],result[32],result[33],result[34],result[35]],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create labels\n",
    "labels_train,labels_test=labels.create_labels()\n",
    "labels_test2=labels_test\n",
    "labels_data=[i for i in range(123)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the machine learning tools\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#Ensemble class scores: random train/test\n",
    "\n",
    "a_score=[0 for i in range(10)]\n",
    "p_score_CP=[0 for i in range(10)]\n",
    "p_score_EL=[0 for i in range(10)]\n",
    "p_score_LN=[0 for i in range(10)]\n",
    "p_score_NE=[0 for i in range(10)]\n",
    "p_score_ST=[0 for i in range(10)]\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = RandomForestClassifier(n_estimators=500, max_depth=500)\n",
    "clf4 = MLPClassifier(hidden_layer_sizes=(500, ), max_iter=900)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('kNN', clf1),('RF', clf3), ('NN', clf4)], voting='soft')#, weights=[2, 1, 2, 1])\n",
    "\n",
    "\n",
    "for x in range(0, 10):\n",
    "    print(x)\n",
    "\n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2)\n",
    "\n",
    "    input_train=np.concatenate([input_HAD[input_idx,:],input_CO1[input_idx,:],input_CO2[input_idx,:],input_ER1[input_idx,:],input_ER2[input_idx,:],input_ER3[input_idx,:],input_KP[input_idx,:]],axis=0)\n",
    "    input_test=np.concatenate([input_HAD[input_test_idx,:],input_CO1[input_test_idx,:],input_CO2[input_test_idx,:],input_ER1[input_test_idx,:],input_ER2[input_test_idx,:],input_ER3[input_test_idx,:],input_KP[input_test_idx,:]],axis=0)\n",
    "\n",
    "    labels_train=labels_traina + labels_traina + labels_traina + labels_traina + labels_traina +labels_traina + labels_traina\n",
    "    labels_test=labels_testa+labels_testa+labels_testa + labels_testa+labels_testa+labels_testa + labels_testa\n",
    "\n",
    "    #choose classifier to be \n",
    "    clf1 = clf1.fit(input_train, labels_train)\n",
    "   # clf2 = clf2.fit(input_train, labels_train)\n",
    "    clf3 = clf3.fit(input_train, labels_train)\n",
    "    clf4 = clf4.fit(input_train, labels_train)\n",
    "    eclf = eclf.fit(input_train, labels_train)\n",
    "    pred=eclf.predict(input_test)\n",
    "    a_score[x]=accuracy_score(labels_test, pred)\n",
    "    p_score_CP[x]=precision_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    p_score_EL[x]=precision_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    p_score_LN[x]=precision_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    p_score_NE[x]=precision_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    p_score_ST[x]=precision_score(labels_test, pred,labels=['ST'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc mean 0.7004608294930875\n",
      "acc max 0.783410138248848\n",
      "acc min 0.5898617511520737\n",
      "CP mean 0.5340839660897647\n",
      "CP max 0.8333333333333334\n",
      "CP min 0.3\n",
      "EL mean 0.5375111749680715\n",
      "EL max 1.0\n",
      "EL min 0.3333333333333333\n",
      "LN mean 0.7963425652596677\n",
      "LN max 1.0\n",
      "LN min 0.6086956521739131\n",
      "NE mean 0.7328792320415253\n",
      "NE max 0.8558558558558559\n",
      "NE min 0.4230769230769231\n",
      "ST mean 0.638219696969697\n",
      "ST max 1.0\n",
      "ST min 0.0\n"
     ]
    }
   ],
   "source": [
    "print('acc mean',np.mean(a_score))\n",
    "print('acc max',np.max(a_score))\n",
    "print('acc min',np.min(a_score))\n",
    "\n",
    "print('CP mean',np.mean(p_score_CP))\n",
    "print('CP max',np.max(p_score_CP))\n",
    "print('CP min',np.min(p_score_CP))\n",
    "\n",
    "print('EL mean',np.mean(p_score_EL))\n",
    "print('EL max',np.max(p_score_EL))\n",
    "print('EL min',np.min(p_score_EL))\n",
    "\n",
    "print('LN mean',np.mean(p_score_LN))\n",
    "print('LN max',np.max(p_score_LN))\n",
    "print('LN min',np.min(p_score_LN))\n",
    "\n",
    "print('NE mean',np.mean(p_score_NE))\n",
    "print('NE max',np.max(p_score_NE))\n",
    "print('NE min',np.min(p_score_NE))\n",
    "\n",
    "print('ST mean',np.mean(p_score_ST))\n",
    "print('ST max',np.max(p_score_ST))\n",
    "print('ST min',np.min(p_score_ST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP [108, 90, 18, 94]\n",
      "EP [45, 22, 0]\n",
      "LN [59, 121, 46, 120, 53, 14, 114, 102, 111, 65]\n",
      "NE [55, 30, 52, 8, 51, 68, 33, 112, 10, 11, 117, 4]\n",
      "ST [86, 69]\n",
      "CP [94, 98, 107, 44]\n",
      "EP [0, 3, 29, 113]\n",
      "LN [79, 14, 77, 74, 28, 13, 59]\n",
      "NE [93, 87, 30, 2, 25, 35, 24, 78, 73, 5, 96, 116, 36, 11, 48]\n",
      "ST [86]\n",
      "CP [107, 81, 106, 95]\n",
      "EP [6, 122, 45]\n",
      "LN [59, 42, 37, 28, 20, 115]\n",
      "NE [57, 17, 88, 43, 10, 60, 116, 64, 89, 35, 23, 50, 49, 39, 52, 48]\n",
      "ST [91, 101]\n",
      "CP [98, 81, 44]\n",
      "EP [0, 34]\n",
      "LN [103, 65, 59, 58, 54, 121, 20, 92, 14]\n",
      "NE [23, 32, 64, 16, 60, 82, 51, 38, 93, 71, 30, 52, 39, 100, 27]\n",
      "ST [101, 61]\n",
      "CP [108, 18, 72, 98, 94, 44]\n",
      "EP [34, 29, 6, 110]\n",
      "LN [20, 7, 42, 14, 46, 58]\n",
      "NE [99, 78, 23, 66, 70, 48, 89, 15, 100, 2, 85, 24, 64]\n",
      "ST [76, 69]\n",
      "CP [108, 62, 106, 95, 44]\n",
      "EP [0, 3, 29, 122]\n",
      "LN [77, 12, 65, 103]\n",
      "NE [100, 35, 4, 17, 1, 73, 112, 88, 70, 33, 82, 52, 30, 25, 40, 116]\n",
      "ST [119, 86]\n",
      "CP [90, 67]\n",
      "EP [83, 3]\n",
      "LN [111, 59, 58, 21, 14]\n",
      "NE [64, 11, 99, 97, 8, 57, 80, 104, 78, 48, 30, 38, 52, 25, 89, 112, 116, 88, 36, 43]\n",
      "ST [69, 101]\n",
      "CP [44, 72, 18, 108, 106]\n",
      "EP [118, 3, 83, 34]\n",
      "LN [21, 54, 7, 12, 53]\n",
      "NE [80, 16, 40, 75, 39, 17, 88, 25, 50, 38, 93, 73, 15, 8]\n",
      "ST [61, 86, 69]\n",
      "CP [90, 94, 72, 107]\n",
      "EP [110, 122, 45, 0]\n",
      "LN [74, 111, 79, 12, 115, 92, 102]\n",
      "NE [43, 56, 23, 39, 112, 48, 47, 30, 33, 78, 2, 41, 104]\n",
      "ST [101, 119, 86]\n",
      "CP [72, 81, 67, 44, 108]\n",
      "EP [122, 0]\n",
      "LN [54, 53, 37, 92, 12, 111]\n",
      "NE [35, 5, 55, 1, 50, 2, 38, 49, 73, 51, 84, 70, 47, 39, 23]\n",
      "ST [76, 101, 119]\n"
     ]
    }
   ],
   "source": [
    "cc=[79,2,5,6,14,8,15,50,18,20]\n",
    "\n",
    "for x in range(10):\n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2,random_state=cc[x])\n",
    "#79 is a good split\n",
    "#2\n",
    "#5 is ok\n",
    "#6\n",
    "#14\n",
    "#8\n",
    "#15\n",
    "#17\n",
    "#18\n",
    "#20\n",
    "\n",
    "\n",
    "#print (input_idx)\n",
    "#print (labels_traina)\n",
    "#print (len(labels_traina))\n",
    "#print (input_test_idx)\n",
    "#print (labels_testa)\n",
    "#print (len(labels_testa))\n",
    "\n",
    "    idx1 = [i for i, x in enumerate(labels_testa) if x=='CP']\n",
    "    idx2 = [i for i, x in enumerate(labels_testa) if x=='EL']\n",
    "    idx3 = [i for i, x in enumerate(labels_testa) if x=='LN']\n",
    "    idx4 = [i for i, x in enumerate(labels_testa) if x=='NE']\n",
    "    idx5 = [i for i, x in enumerate(labels_testa) if x=='ST']\n",
    "\n",
    "    a=[input_test_idx[i] for i in idx1]\n",
    "    print ('CP' , a)\n",
    "    a=[input_test_idx[i] for i in idx2]\n",
    "    print ('EP' , a)\n",
    "    a=[input_test_idx[i] for i in idx3]\n",
    "    print ('LN' , a)\n",
    "    a=[input_test_idx[i] for i in idx4]\n",
    "    print ('NE' , a)\n",
    "    a=[input_test_idx[i] for i in idx5]\n",
    "    print ('ST' , a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#train test split on data selected to be a good split\n",
    "\n",
    "a_score=[0 for i in range(10)]\n",
    "p_score_CP=[0 for i in range(10)]\n",
    "p_score_EL=[0 for i in range(10)]\n",
    "p_score_LN=[0 for i in range(10)]\n",
    "p_score_NE=[0 for i in range(10)]\n",
    "p_score_ST=[0 for i in range(10)]\n",
    "clf_score=[0 for i in range(10)]\n",
    "\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = RandomForestClassifier(n_estimators=500, max_depth=500)\n",
    "clf4 = MLPClassifier(hidden_layer_sizes=(500, ), max_iter=900)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('kNN', clf1),('RF', clf3), ('NN', clf4)], voting='soft')#, weights=[2, 1, 2, 1])\n",
    "#79 is a good split\n",
    "#2\n",
    "#5 is ok\n",
    "#6\n",
    "#14\n",
    "#8\n",
    "#15\n",
    "#17\n",
    "#18\n",
    "#20\n",
    "cc=[79,2,5,6,14,8,15,50,18,20]\n",
    "\n",
    "\n",
    "for x in range(10):\n",
    "    print (x)\n",
    "    \n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2,random_state=cc[x])\n",
    "\n",
    "    input_train=np.concatenate([input_HAD[input_idx,:],input_CO1[input_idx,:],input_CO2[input_idx,:],input_ER1[input_idx,:],input_ER2[input_idx,:],input_ER3[input_idx,:],input_KP[input_idx,:]],axis=0)\n",
    "    input_test=np.concatenate([input_HAD[input_test_idx,:],input_CO1[input_test_idx,:],input_CO2[input_test_idx,:],input_ER1[input_test_idx,:],input_ER2[input_test_idx,:],input_ER3[input_test_idx,:],input_KP[input_test_idx,:]],axis=0)\n",
    "\n",
    "    labels_train=labels_traina + labels_traina + labels_traina + labels_traina + labels_traina +labels_traina + labels_traina\n",
    "    labels_test=labels_testa+labels_testa+labels_testa + labels_testa+labels_testa+labels_testa + labels_testa\n",
    "\n",
    "    #choose classifier to be \n",
    "    clf1 = clf1.fit(input_train, labels_train)\n",
    "  #  clf2 = clf2.fit(input_train, labels_train)\n",
    "    clf3 = clf3.fit(input_train, labels_train)\n",
    "    clf4 = clf4.fit(input_train, labels_train)\n",
    "    eclf = eclf.fit(input_train, labels_train)\n",
    "    pred=eclf.predict(input_test)\n",
    "    a_score[x]=accuracy_score(labels_test, pred)\n",
    "    p_score_CP[x]=precision_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    p_score_EL[x]=precision_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    p_score_LN[x]=precision_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    p_score_NE[x]=precision_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    p_score_ST[x]=precision_score(labels_test, pred,labels=['ST'], average=None)\n",
    "    clf_score[x]=cross_val_score(eclf, input_train, labels_train, cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc mean 0.6944700460829493\n",
      "acc max 0.7926267281105991\n",
      "acc min 0.5622119815668203\n",
      "CP mean 0.5472507355344883\n",
      "CP max 0.7857142857142857\n",
      "CP min 0.391304347826087\n",
      "EL mean 0.4157680781162755\n",
      "EL max 0.5714285714285714\n",
      "EL min 0.23333333333333334\n",
      "LN mean 0.8259379722210994\n",
      "LN max 1.0\n",
      "LN min 0.5531914893617021\n",
      "NE mean 0.7634164008810718\n",
      "NE max 0.8703703703703703\n",
      "NE min 0.6565656565656566\n",
      "ST mean 0.6131313131313132\n",
      "ST max 1.0\n",
      "ST min 0.0\n",
      "clf mean 0.939315649224806\n",
      "clf max 0.9627180232558139\n",
      "clf min 0.9255087209302324\n"
     ]
    }
   ],
   "source": [
    "print('acc mean',np.mean(a_score))\n",
    "print('acc max',np.max(a_score))\n",
    "print('acc min',np.min(a_score))\n",
    "\n",
    "print('CP mean',np.mean(p_score_CP))\n",
    "print('CP max',np.max(p_score_CP))\n",
    "print('CP min',np.min(p_score_CP))\n",
    "\n",
    "print('EL mean',np.mean(p_score_EL))\n",
    "print('EL max',np.max(p_score_EL))\n",
    "print('EL min',np.min(p_score_EL))\n",
    "\n",
    "print('LN mean',np.mean(p_score_LN))\n",
    "print('LN max',np.max(p_score_LN))\n",
    "print('LN min',np.min(p_score_LN))\n",
    "\n",
    "print('NE mean',np.mean(p_score_NE))\n",
    "print('NE max',np.max(p_score_NE))\n",
    "print('NE min',np.min(p_score_NE))\n",
    "\n",
    "print('ST mean',np.mean(p_score_ST))\n",
    "print('ST max',np.max(p_score_ST))\n",
    "print('ST min',np.min(p_score_ST))\n",
    "\n",
    "print('clf mean',np.mean(clf_score))\n",
    "print('clf max',np.max(clf_score))\n",
    "print('clf min',np.min(clf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-12-155cb73e5226>, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-155cb73e5226>\"\u001b[0;36m, line \u001b[0;32m56\u001b[0m\n\u001b[0;31m    clf_score[x]=cross_val_score(eclf, input_train, labels_train, cv=5).mean()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#train test split on data selected to be a good split: test only one dataset HadISST\n",
    "\n",
    "\n",
    "a_score=[0 for i in range(10)]\n",
    "p_score_CP=[0 for i in range(10)]\n",
    "p_score_EL=[0 for i in range(10)]\n",
    "p_score_LN=[0 for i in range(10)]\n",
    "p_score_NE=[0 for i in range(10)]\n",
    "p_score_ST=[0 for i in range(10)]\n",
    "clf_score=[0 for i in range(10)]\n",
    "\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = RandomForestClassifier(n_estimators=500, max_depth=500)\n",
    "clf4 = MLPClassifier(hidden_layer_sizes=(500, ), max_iter=900)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('kNN', clf1),('RF', clf3), ('NN', clf4)], voting='soft')#, weights=[2, 1, 2, 1])\n",
    "\n",
    "#79 is a good split\n",
    "#2\n",
    "#5 is ok\n",
    "#6\n",
    "#14\n",
    "#8\n",
    "#15\n",
    "#17\n",
    "#18\n",
    "#20\n",
    "cc=[79,2,5,6,14,8,15,50,18,20]\n",
    "\n",
    "\n",
    "for x in range(10):\n",
    "    print (x)\n",
    "    \n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2,random_state=cc[x])\n",
    "\n",
    "    input_train=np.concatenate([input_HAD[input_idx,:],input_CO1[input_idx,:],input_CO2[input_idx,:],input_ER1[input_idx,:],input_ER2[input_idx,:],input_ER3[input_idx,:],input_KP[input_idx,:]],axis=0)\n",
    "    input_test=np.concatenate([input_HAD[input_test_idx,:]])#,input_CO1[input_test_idx,:],input_CO2[input_test_idx,:],input_ER1[input_test_idx,:],input_ER2[input_test_idx,:],input_ER3[input_test_idx,:],input_KP[input_test_idx,:]],axis=0)\n",
    "\n",
    "    labels_train=labels_traina + labels_traina + labels_traina + labels_traina + labels_traina +labels_traina + labels_traina\n",
    "    labels_test=labels_testa#+labels_testa+labels_testa + labels_testa+labels_testa+labels_testa + labels_testa\n",
    "\n",
    "    #choose classifier to be \n",
    "    clf1 = clf1.fit(input_train, labels_train)\n",
    "   # clf2 = clf2.fit(input_train, labels_train)\n",
    "    clf3 = clf3.fit(input_train, labels_train)\n",
    "    clf4 = clf4.fit(input_train, labels_train)\n",
    "    eclf = eclf.fit(input_train, labels_train)\n",
    "    pred=eclf.predict(input_test)\n",
    "    a_score[x]=accuracy_score(labels_test, pred)\n",
    "    p_score_CP[x]=precision_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    p_score_EL[x]=precision_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    p_score_LN[x]=precision_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    p_score_NE[x]=precision_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    p_score_ST[x]=precision_score(labels_test, pred,labels=['ST'], average=None)\n",
    "       clf_score[x]=cross_val_score(eclf, input_train, labels_train, cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('acc mean',np.mean(a_score))\n",
    "print('acc max',np.max(a_score))\n",
    "print('acc min',np.min(a_score))\n",
    "\n",
    "print('CP mean',np.mean(p_score_CP))\n",
    "print('CP max',np.max(p_score_CP))\n",
    "print('CP min',np.min(p_score_CP))\n",
    "\n",
    "print('EL mean',np.mean(p_score_EL))\n",
    "print('EL max',np.max(p_score_EL))\n",
    "print('EL min',np.min(p_score_EL))\n",
    "\n",
    "print('LN mean',np.mean(p_score_LN))\n",
    "print('LN max',np.max(p_score_LN))\n",
    "print('LN min',np.min(p_score_LN))\n",
    "\n",
    "print('NE mean',np.mean(p_score_NE))\n",
    "print('NE max',np.max(p_score_NE))\n",
    "print('NE min',np.min(p_score_NE))\n",
    "\n",
    "\n",
    "print('ST mean',np.mean(p_score_ST))\n",
    "print('ST max',np.max(p_score_ST))\n",
    "print('ST min',np.min(p_score_ST))\n",
    "\n",
    "print('clf mean',np.mean(clf_score))\n",
    "print('clf max',np.max(clf_score))\n",
    "print('clf min',np.min(clf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split on data selected to be a good split: train and test only one dataset HadISST\n",
    "\n",
    "\n",
    "a_score=[0 for i in range(10)]\n",
    "p_score_CP=[0 for i in range(10)]\n",
    "p_score_EL=[0 for i in range(10)]\n",
    "p_score_LN=[0 for i in range(10)]\n",
    "p_score_NE=[0 for i in range(10)]\n",
    "p_score_ST=[0 for i in range(10)]\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = RandomForestClassifier(n_estimators=500, max_depth=500)\n",
    "clf4 = MLPClassifier(hidden_layer_sizes=(500, ), max_iter=900)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('kNN', clf1),('RF', clf3), ('NN', clf4)], voting='soft')#, weights=[2, 1, 2, 1])\n",
    "#79 is a good split\n",
    "#2\n",
    "#5 is ok\n",
    "#6\n",
    "#14\n",
    "#8\n",
    "#15\n",
    "#17\n",
    "#18\n",
    "#20\n",
    "cc=[79,2,5,6,14,8,15,50,18,20]\n",
    "\n",
    "\n",
    "for x in range(10):\n",
    "    print (x)\n",
    "    \n",
    "    input_idx, input_test_idx, labels_traina, labels_testa=train_test_split(labels_data,labels_test2,random_state=cc[x])\n",
    "\n",
    "    input_train=np.concatenate([input_HAD[input_idx,:]])#,input_CO1[input_idx,:],input_CO2[input_idx,:],input_ER1[input_idx,:],input_ER2[input_idx,:],input_ER3[input_idx,:],input_KP[input_idx,:]],axis=0)\n",
    "    input_test=np.concatenate([input_HAD[input_test_idx,:]])#,input_CO1[input_test_idx,:],input_CO2[input_test_idx,:],input_ER1[input_test_idx,:],input_ER2[input_test_idx,:],input_ER3[input_test_idx,:],input_KP[input_test_idx,:]],axis=0)\n",
    "\n",
    "    labels_train=labels_traina# + labels_traina + labels_traina + labels_traina + labels_traina +labels_traina + labels_traina\n",
    "    labels_test=labels_testa#+labels_testa+labels_testa + labels_testa+labels_testa+labels_testa + labels_testa\n",
    "\n",
    "    #choose classifier to be \n",
    "    clf1 = clf1.fit(input_train, labels_train)\n",
    "   # clf2 = clf2.fit(input_train, labels_train)\n",
    "    clf3 = clf3.fit(input_train, labels_train)\n",
    "    clf4 = clf4.fit(input_train, labels_train)\n",
    "    eclf = eclf.fit(input_train, labels_train)\n",
    "    pred=eclf.predict(input_test)\n",
    "    a_score[x]=accuracy_score(labels_test, pred)\n",
    "    p_score_CP[x]=precision_score(labels_test, pred,labels=['CP'], average=None)\n",
    "    p_score_EL[x]=precision_score(labels_test, pred,labels=['EL'], average=None)\n",
    "    p_score_LN[x]=precision_score(labels_test, pred,labels=['LN'], average=None)\n",
    "    p_score_NE[x]=precision_score(labels_test, pred,labels=['NE'], average=None)\n",
    "    p_score_ST[x]=precision_score(labels_test, pred,labels=['ST'], average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('acc mean',np.mean(a_score))\n",
    "print('acc max',np.max(a_score))\n",
    "print('acc min',np.min(a_score))\n",
    "\n",
    "print('CP mean',np.mean(p_score_CP))\n",
    "print('CP max',np.max(p_score_CP))\n",
    "print('CP min',np.min(p_score_CP))\n",
    "\n",
    "print('EL mean',np.mean(p_score_EL))\n",
    "print('EL max',np.max(p_score_EL))\n",
    "print('EL min',np.min(p_score_EL))\n",
    "\n",
    "print('LN mean',np.mean(p_score_LN))\n",
    "print('LN max',np.max(p_score_LN))\n",
    "print('LN min',np.min(p_score_LN))\n",
    "\n",
    "print('NE mean',np.mean(p_score_NE))\n",
    "print('NE max',np.max(p_score_NE))\n",
    "print('NE min',np.min(p_score_NE))\n",
    "\n",
    "print('ST mean',np.mean(p_score_ST))\n",
    "print('ST max',np.max(p_score_ST))\n",
    "print('ST min',np.min(p_score_ST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
